{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem comes from OpenAI's [Requests for Research 2.0](https://blog.openai.com/requests-for-research-2/). And the description of this problem is as following:\n",
    "\n",
    "----\n",
    "\n",
    "Train an LSTM to solve the XOR problem: that is, given a sequence of bits, determine its parity. The LSTM should consume the sequence, one bit at a time, and then output the correct answer at the sequenceâ€™s end. Test the two approaches below:\n",
    "\n",
    "Generate a dataset of random 100,000 binary strings of length 50. Train the LSTM; what performance do you get?\n",
    "Generate a dataset of random 100,000 binary strings, where the length of each string is independently and randomly chosen between 1 and 50. Train the LSTM. Does it succeed? What explains the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep results reproducible, we need to control all the random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data generation and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state=41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset(dataset_size, MAX_LEN, variable_length, random_state):\n",
    "    numpy.random.seed(random_state)\n",
    "    dataset=[]\n",
    "    targets=[]\n",
    "    for i in tqdm(range(dataset_size)):\n",
    "        if variable_length:\n",
    "            length=numpy.random.randint(2,MAX_LEN+1)\n",
    "        else:\n",
    "            length=MAX_LEN\n",
    "        dataset.append(numpy.random.randint(0,2,size=(length)))\n",
    "        labels=int(sum(dataset[-1])%2)\n",
    "        targets.append(labels)\n",
    "    return dataset,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec52a280e7d44e7888fc1c7c6dd7f89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset,targets=generate_dataset(100000,50,True,random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train+valid and test, then we can split train+valid into train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(dataset, targets, test_size=0.2, random_state=random_state)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.25, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the performance of our baseline: Logistic Regression.\n",
    "As the length could be variable, we need to padding those shorter sequences with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padding(x,length):\n",
    "    return list(x)+[0]*(length-len(x))\n",
    "def test_baseline(X_train, X_test, y_train, y_test):\n",
    "    length=[len(x) for x in X_train]\n",
    "    max_length=max(length)\n",
    "    X_train=[padding(x,max_length) for x in X_train]\n",
    "    X_test=[padding(x,max_length) for x in X_test]\n",
    "    clf=LogisticRegression(C=0.01, penalty='l1')\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    return accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy is 0.4988\n"
     ]
    }
   ],
   "source": [
    "baseline_accuracy=test_baseline(X_train, X_test, y_train, y_test)\n",
    "print('Baseline accuracy is %0.4f'%baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to generate batch data. Here we use class Dataset provided by pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    sequences=numpy.array([d[0] for d in data])\n",
    "    labels=numpy.array([d[1] for d in data])\n",
    "    return sequences,labels\n",
    "\n",
    "class XOR_Dataset(Dataset):\n",
    "    def __init__(self, dataset,target):\n",
    "        self.dataset=dataset\n",
    "        self.target=target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx],self.target[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define our LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM_CLF(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_size, use_cuda):\n",
    "        super(LSTM_CLF, self).__init__()\n",
    "        self.embedding = nn.Embedding(3, emb_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "        )\n",
    "        self.clf=nn.Sequential(\n",
    "            nn.Linear(hidden_size,2),\n",
    "        )\n",
    "        self.padding_idx=2\n",
    "        self.use_cuda=use_cuda\n",
    "        if self.use_cuda:\n",
    "            self.cuda()\n",
    "\n",
    "    def forward(self, sequences, lengths):\n",
    "        self.embedding.weight.data[self.padding_idx]=0\n",
    "        if self.use_cuda:\n",
    "            sequences=sequences.cuda()\n",
    "        sequences=Variable(sequences)\n",
    "        emb=self.embedding(sequences)\n",
    "        pack = pack_padded_sequence(emb, lengths, batch_first=True)\n",
    "        output, hidden = lstm.rnn(pack)\n",
    "        hidden=hidden[0].squeeze()\n",
    "        return self.clf(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_lstm(lstm,X_test,y_test,use_cuda):\n",
    "    sequences,labels,lengths=sort_and_padding(X_test,y_test,use_cuda)\n",
    "    final_layer=lstm(sequences,lengths)\n",
    "    y_pred=final_layer.topk(1)[1].cpu().data.numpy()\n",
    "    return accuracy_score(labels,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle variable length of the input sequences, we need to sort each batch according to their length.\n",
    "We also need to rearrange the labels accordig to the order of sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_and_padding(sequences,labels,use_cuda):\n",
    "    '''\n",
    "    sequences: numpy.array\n",
    "    labels:numpy.array\n",
    "    '''\n",
    "    sequences=numpy.array(sequences)\n",
    "    labels=numpy.array(labels)\n",
    "    lengths = [len(x) for x in sequences]\n",
    "    lengths=Variable(torch.FloatTensor(lengths))\n",
    "    ordered_len,ordered_idx=lengths.sort(0, descending=True)\n",
    "    ordered_len=ordered_len.cpu().data.numpy().astype(numpy.int32)\n",
    "    sequences=sequences[ordered_idx.cpu().data.numpy()]\n",
    "    labels=labels[ordered_idx.cpu().data.numpy()]\n",
    "    for i in range(sequences.shape[0]):\n",
    "        padding_size=int(ordered_len[0]-ordered_len[i])\n",
    "        sequences[i]=numpy.append(sequences[i],numpy.ones(padding_size)*2)\n",
    "        sequences[i]=list(sequences[i].astype(numpy.int32))\n",
    "    sequences=numpy.array(list(sequences))\n",
    "    sequences=torch.LongTensor(sequences)\n",
    "    labels=torch.from_numpy(labels)\n",
    "    if use_cuda:\n",
    "        sequences=sequences.cuda()\n",
    "        labels=labels.cuda()\n",
    "    return sequences,labels,ordered_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_dim=5\n",
    "hidden_size=10\n",
    "use_cuda=False\n",
    "MAX_ITER=11\n",
    "lr=0.001\n",
    "losses=[]\n",
    "best_loss=10000000\n",
    "valid_every=100\n",
    "idx=0\n",
    "batch_size=64\n",
    "lstm_train_dataset=XOR_Dataset(X_train,y_train)\n",
    "lstm=LSTM_CLF(emb_dim,hidden_size,use_cuda)\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=lr)\n",
    "criteria=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33816dcd986449e7be70ce4703da0479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop_training=False\n",
    "for epoch in tqdm(range(MAX_ITER)):\n",
    "    lstm_train=iter(DataLoader(lstm_train_dataset,batch_size=batch_size,collate_fn=collate_fn))\n",
    "    for sequences,labels in lstm_train:\n",
    "        sequences,labels,lengths=sort_and_padding(sequences,labels,use_cuda)\n",
    "        idx+=1\n",
    "        optimizer.zero_grad()\n",
    "        labels=Variable(labels)\n",
    "        final_layer=lstm.forward(sequences,lengths)\n",
    "        loss=criteria(final_layer,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.cpu().data.numpy()[0])\n",
    "        if idx%valid_every==0:\n",
    "            sequences,labels,lengths=sort_and_padding(X_valid,y_valid,use_cuda)\n",
    "            labels=Variable(labels)\n",
    "            final_layer=lstm.forward(sequences,lengths)\n",
    "            loss=criteria(final_layer,labels)\n",
    "            loss=loss.cpu().data.numpy()[0]\n",
    "            if loss<best_loss:\n",
    "                best_valid_accuracy=test_lstm(lstm,X_valid,y_valid,use_cuda)\n",
    "                if best_valid_accuracy==1.0:\n",
    "                    print(test_lstm(lstm,X_test,y_test,use_cuda))\n",
    "                    stop_training=True\n",
    "                    break\n",
    "                print(test_lstm(lstm,X_test,y_test,use_cuda))\n",
    "    if stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9bf8ff3710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences,labels,lengths=sort_and_padding(X_test,y_test,use_cuda)\n",
    "labels=Variable(labels)\n",
    "final_layer=lstm(sequences,lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(test_lstm(lstm,X_test,y_test,use_cuda))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
